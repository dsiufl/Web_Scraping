{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please make sure you signed in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Web Scraping is a very useful method used by data scientists to gather data from websites. This workshop will introduce the basics of web scraping and review common web scraping methodologies. Although there are many different ways to scrape data from websites we will cover some o the most popularly used libraries that python has to offer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to stay out of jail\n",
    "\n",
    "Web Scraping is one of those legal gray areas (sadly). Make sure the site you are scraping is public domain, other wise make sure you have approval from the site's owner. Even with public domain be careful as sometimes your web scrape can overlook a site's terms of agreement. \n",
    "\n",
    "Ex.) LinkedIn vs. Doe Defendants. LinkedIn is suing 100 anonymous users for the following violations:\n",
    "\n",
    "-Computer Fraud and Abuse Act (CFAA)\n",
    "\n",
    "-California Penal Code\n",
    "\n",
    "-Digital Millennium Copyright Act (DMCA)\n",
    "\n",
    "\n",
    "A lot of web scraping/crawling rules will be listed in a sites robots.txt file which I will show you how to access. One example of restricion would be the crawl rate which tell you how many request you can per minute. This is to keep your crawl from overloading the server (simply add a delay of 10 sec between requests in code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTML Basics Review\n",
    "\n",
    "HTML stands for Hypertext Markup Language. \n",
    "\n",
    "It is used to describe the structure of web pages. It uses HTML elements that are represented by tags. This are a few of the HTML elements that are available but there are many more that can be used. Familiarity with different tags and thier functions are good know, but it is not as important as knowing the structure of HTML.\n",
    "\n",
    "The following is an example of the HTML code structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   <!DOCTYPE html>\n",
    "#   <html>\n",
    "#      <head>\n",
    "#          <title>Page Title</title>\n",
    "#      </head>\n",
    "#      <body>\n",
    "#         <h1>My First Heading</h1>\n",
    "#         <p>My first paragraph.</p>\n",
    "#         <input type=\"button\" onclick=\"location.href='http://google.com'\" value=\"Go to Google\">\n",
    "#      </body>\n",
    "#   </html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules\n",
    "\n",
    "Here there are two important libraries we will be using. BeautifulSoup allows us to work with HTML easily. The second is requests which we will use to gather the HTML from the website of our choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # importing the BeautifulSoup: Helps parse and \"beautify\" HTML \n",
    "                      # importing the urlopen: Helps make web client to sites."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you get an error when running this block, you may not have the bs4 library installed. To do this open up Anaconda Prompt (or Terminal if on Mac) and type <code>pip install beautifulsoup4</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a Request\n",
    "\n",
    "This is how to make a request and download the HTML from the website. We will be using Wikipedia for our example as it is a fairly easy site to scrape from. Lets use the machine learning wiki at: https://en.wikipedia.org/wiki/Machine_learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the .text attribute shows the text stores in this req object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basics of BeatifulSoup4 \n",
    "\n",
    "So we now have a variable 'results' that basically spits out the HTML from this website. This is kind of daunting and unhelpful but luckily we can use BeautifulSoup for this. This library is essentially an HTML \"beautifier\" that makes working with HTML bearable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets convert our object to type requests to one of type bs4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select\n",
    "\n",
    "We can select certain tags from HTML. Helpful to use the HTML inspector in a web browser like Chrome or Safari. In this case let's select all the headers on the page so we can see the different topics that the wiki page contains. Select will pull all the items given the tag and put them into an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting all the headlines\n",
    "# print(type(soup.select(\".mw-headline\")[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all the titles in readable format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping for Real\n",
    "\n",
    "Now that we have the basics, lets try web scraping a real site! With permission of course. Lets use this website we are allowed to scrape. Here is the link: http://books.toscrape.com/catalogue/category/books_1/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lets get all the product information we can. Seems like each item is separated into a \"product_pod\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scraping titles**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scraping prices**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scraping availability**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping multiple pages\n",
    "\n",
    "Sadly there isn't really an easy function to do this. Atleast none that I have seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can't easily include the first page in the link becasue it has \"index.html\" rather than the regular file\n",
    "\n",
    "# Loops through a formatted url string. Will take a while to run\n",
    "\n",
    "for page in range(2,51):\n",
    "    url = 'http://books.toscrape.com/catalogue/category/books_1/page-'+str(page)+'.html'\n",
    "    results = req.get(url)\n",
    "    soup = bs(results.text, 'lxml')\n",
    "    titles.extend([x.text for x in soup.find_all('h3')])\n",
    "    price.extend([x.text[2:] for x in soup.find_all('p', attrs = {'class': 'price_color'})])\n",
    "    instock.extend([x.text[15:23] for x in soup.find_all('p', attrs = {'class': 'instock availability'})])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating your data\n",
    "\n",
    "Now that we have retrieved our data lets create our dataframe and do some cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember that the prices were store as Strings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets clean this real quick\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "\n",
    "Lets make a boxplot of all the prices to check for outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set(style = 'darkgrid', color_codes = True)\n",
    "f, ax = plt.subplots(figsize=(13, 3))\n",
    "sns.despine(f, left=True, bottom=True)\n",
    "\n",
    "boxplt = sns.boxplot(books['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AxesSubplot(0.125,0.11;0.775x0.77)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thank You for Coming!\n",
    "\n",
    "Visit us at https://www.dsiufl.org"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
